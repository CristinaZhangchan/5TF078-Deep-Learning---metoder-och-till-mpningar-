{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dR_j4aATMDnm"
      },
      "source": [
        "# 5TF078 Deep Learning Course\n",
        "## Excercise 4 Sentiment analysis on IMDB\n",
        "Created by Tomas Nordström, Umeå University\n",
        "\n",
        "Revisions:\n",
        "* 2023-11-24 Initial version based on earlier versions of this Excercise /ToNo\n",
        "* 2023-12-03 Prepare for release /ToNo\n",
        "* 2023-12-04 Work around a bug that made installing KerasNLP force a non-GPU version of tensorflow /ToNo\n",
        "* 2023-12-07 Since two days there is is a bug in keras-nlp.git \"No module named 'keras_nlp.models.electra'\", so an updated installation method is implemented. /ToNo\n",
        "* 2024-01-31 A new way of installing keras_nlp, as the previous one began to crash in the last weeks.\n",
        "* 2024-03-24 Updated tests for Kaggle. /Tomas\n",
        "* 2024-05-05 Added missing \"import time\" & \"import os\"; Forced a loading of dev versions of Keras/TF as current version do not handle LSTM well. /Tomas\n",
        "* 2024-11-29 Updated the VG part (removed LSTM with a pretrained word2vec). /Tomas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PxscrwgJjlCJ"
      },
      "source": [
        "Much of this is based on the KerasNLP getting started documentation:\n",
        "https://keras.io/guides/keras_nlp/getting_started/\n",
        "\n",
        "Other code examples used:\n",
        "* https://github.com/fchollet/deep-learning-with-python-notebooks/blob/master/first_edition/6.2-understanding-recurrent-neural-networks.ipynb\n",
        "* https://keras.io/examples/nlp/fnet_classification_with_keras_nlp/\n",
        "* https://www.tensorflow.org/text/tutorials/text_classification_rnn\n",
        "* https://keras.io/examples/nlp/text_classification_from_scratch/\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5ukHWI3M_NE"
      },
      "source": [
        "# First we initilize our Python environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uxbkzDfCJfIB"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "import time\n",
        "\n",
        "### Is this notebook running on Colab?\n",
        "IS_COLAB = \"google.colab\" in sys.modules\n",
        "\n",
        "### Is this notebook running on Kaggle?\n",
        "# Fool Kaggle into making kaggle_secrets avaiable\n",
        "try:\n",
        "    import kaggle_secrets\n",
        "except ImportError as e:\n",
        "    pass\n",
        "# Now we can test for Kaggle\n",
        "IS_KAGGLE = \"kaggle_secrets\" in sys.modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QVqLmHeDfcSE",
        "outputId": "fd38a542-c29a-4e1f-de98-3eec32917a6d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras-nlp==0.12.1 in /usr/local/lib/python3.10/dist-packages (0.12.1)\n",
            "Requirement already satisfied: tensorflow==2.18.0 in /usr/local/lib/python3.10/dist-packages (2.18.0)\n",
            "Requirement already satisfied: tf-keras==2.18.0 in /usr/local/lib/python3.10/dist-packages (2.18.0)\n",
            "Requirement already satisfied: keras-core in /usr/local/lib/python3.10/dist-packages (from keras-nlp==0.12.1) (0.1.7)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras-nlp==0.12.1) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras-nlp==0.12.1) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras-nlp==0.12.1) (24.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from keras-nlp==0.12.1) (2024.9.11)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras-nlp==0.12.1) (13.9.4)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from keras-nlp==0.12.1) (0.1.8)\n",
            "Requirement already satisfied: kagglehub in /usr/local/lib/python3.10/dist-packages (from keras-nlp==0.12.1) (0.3.4)\n",
            "Requirement already satisfied: tensorflow-text in /usr/local/lib/python3.10/dist-packages (from keras-nlp==0.12.1) (2.18.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.18.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.18.0) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.18.0) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.18.0) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.18.0) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.18.0) (3.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.18.0) (4.25.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.18.0) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.18.0) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.18.0) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.18.0) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.18.0) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.18.0) (1.17.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.18.0) (1.68.1)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.18.0) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.18.0) (3.5.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.18.0) (3.12.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.18.0) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.18.0) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.18.0) (0.45.1)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.5.0->tensorflow==2.18.0) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.5.0->tensorflow==2.18.0) (0.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow==2.18.0) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow==2.18.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow==2.18.0) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow==2.18.0) (2024.8.30)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.19,>=2.18->tensorflow==2.18.0) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.19,>=2.18->tensorflow==2.18.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.19,>=2.18->tensorflow==2.18.0) (3.1.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kagglehub->keras-nlp==0.12.1) (4.66.6)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras-nlp==0.12.1) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras-nlp==0.12.1) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras-nlp==0.12.1) (0.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow==2.18.0) (3.0.2)\n",
            "Time to install everything: 9.5\n",
            "You (most likely) need to restart the runtime now!\n"
          ]
        }
      ],
      "source": [
        "# As of 2024-05-05 older Keras versions is having problem with our LSTM code, and we need to install the dev version of Keras and TF\n",
        "# This is true for both Colab (Keras 2.15) and Kaggle (Keras 3.0.5)\n",
        "if IS_COLAB or IS_KAGGLE:\n",
        "    # Colab already has Keras 3.5 and Tensorflow 2.17, only need Keras-NLP\n",
        "    # Version 0.12.1 was chosen based on what keras-nlp-nightly probably was\n",
        "    # when this block was introduced.\n",
        "    # However, installing keras-nlp==0.12.1 causes Tensorflow 2.18 to be\n",
        "    # pulled in, so lets be explicit about it.\n",
        "    # Also, tf-keras does not automatically update from 2.17 to 2.18, so we\n",
        "    # need to manually specify that too.\n",
        "    start = time.time()\n",
        "    !pip3 install keras-nlp==0.12.1 tensorflow==2.18.0 tf-keras==2.18.0\n",
        "    end = time.time()\n",
        "    print(f\"Time to install everything: {end - start:.1f}\",)\n",
        "    print(\"You (most likely) need to restart the runtime now!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OI1UZFS4JgSc",
        "outputId": "94b5e112-0795-4c35-c32f-ed9338f23e4c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Keras version: 3.5.0\n",
            "TensorFlow version: 2.18.0\n"
          ]
        }
      ],
      "source": [
        "# Set up Keras backend\n",
        "os.environ[\"KERAS_BACKEND\"] = \"jax\" # Also tensorflow,jax,pytorch for Keras 3.0\n",
        "\n",
        "# Make TF less noisy\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # or any {'0', '1', '2'}\n",
        "\n",
        "# Import Keras/TF libraries\n",
        "import keras\n",
        "print('Keras version:', keras.__version__)\n",
        "\n",
        "import tensorflow as tf\n",
        "print('TensorFlow version:', tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_UOuCIOV6Hta",
        "outputId": "d495278d-4356-4256-bd0f-e106aeeea9c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TF-device: Only CPU!\n",
            "As long as we are using Keras and Jax, this will not affect us in this notebook!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-12-85f8acb7f854>:26: DeprecationWarning: jax.lib.xla_bridge.get_backend is deprecated; use jax.extend.backend.get_backend.\n",
            "  print(f'Jax backend: {xla_bridge.get_backend().platform}')\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Jax backend: cpu\n"
          ]
        }
      ],
      "source": [
        "# Test for GPU and determine what GPU we have\n",
        "import os\n",
        "import platform\n",
        "import subprocess\n",
        "gpu_name = tf.test.gpu_device_name()\n",
        "if gpu_name != '':\n",
        "    print('TF-GPU-devname:',tf.test.gpu_device_name())\n",
        "    sys_details = tf.sysconfig.get_build_info()\n",
        "    physical_devices = tf.config.list_physical_devices('GPU')\n",
        "    print(\"Num GPUs:\", len(physical_devices))\n",
        "    if platform.system() == \"Darwin\":\n",
        "        print('GPU on Mac!')\n",
        "    else:\n",
        "        cuda_version = sys_details[\"cuda_version\"]\n",
        "        print('TF-cuda version:',cuda_version)\n",
        "        if len(physical_devices)>0:\n",
        "            process = subprocess.Popen(['nvidia-smi','-L'], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "            print(process.communicate())\n",
        "else:\n",
        "    print('TF-device: Only CPU!')\n",
        "    print('As long as we are using Keras and Jax, this will not affect us in this notebook!')\n",
        "\n",
        "# Test for Jax backend\n",
        "# https://github.com/google/jax/issues/971\n",
        "from jax.lib import xla_bridge\n",
        "print(f'Jax backend: {xla_bridge.get_backend().platform}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D06IYSsfJagA"
      },
      "outputs": [],
      "source": [
        "# Helper libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Matlab plotting\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G12v5kdSPCbe"
      },
      "source": [
        "# Read in the data\n",
        "\n",
        "The IMDb dataset consists of 50,000 movie reviews in English\n",
        "(25,000 for training, 25,000 for testing) extracted from the famous Internet Movie Database, along with a simple binary target for each review indicating whether it is negative (0) or positive (1).\n",
        "\n",
        "There are many alternatives to get the data:\n",
        "* Use the Keras built in [IMDB database](https://keras.io/api/datasets/imdb/) from keras.\n",
        "* Use the TensorFlow Datasets library for [IMDB reviews](https://www.tensorflow.org/datasets/catalog/imdb_reviews)\n",
        "* Or as we are going to do, read the [orginal dataset](http://ai.stanford.edu/~amaas/data/sentiment/)\n",
        "\n",
        "We use to orginal data to see how one can read data (text) files from directories directly. How one can do preprocessing on datasets. The raw data is also preferred when we later want to work with BERT as a transfer learning model. (The Keras data have already preprocessed words into integers.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZnyQdCdVj7nJ",
        "outputId": "97d7f86d-f99a-4a60-ce80-c8388ddd2244"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['test', 'imdb.vocab', 'imdbEr.txt', 'README', 'train']\n",
            "['pos', 'neg', 'labeledBow.feat', 'urls_unsup.txt', 'urls_pos.txt', 'unsupBow.feat', 'urls_neg.txt']\n",
            "['pos', 'neg', 'labeledBow.feat', 'urls_pos.txt', 'urls_neg.txt']\n",
            "Example of a postive review: I read the book and saw the movie. Both excellent. The movie is diamond among coals during this era. Liebman and Selby dominate the screen and communicate the intensity of their characters without flaw. This film should have made them stars. Shame on the studio for not putting everything they had behind this film. It could have easily been a franchise. Release on DVD is a must and a worthy remake would revive this film. Look for it in your TV guide and if you see it listed, no matter how late, watch it. You won't be disappointed. Do yourself another favor - read the book (same title). It'll blow you away. Times have changed dramatically since those days, or at least we like to think they have.\n"
          ]
        }
      ],
      "source": [
        "# Reading the database from the source\n",
        "# following https://keras.io/guides/keras_nlp/getting_started/\n",
        "if not os.path.exists('./aclImdb_v1.tar.gz'):\n",
        "  !curl -O https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
        "  !tar -xf aclImdb_v1.tar.gz\n",
        "  !# Remove unsupervised examples\n",
        "  !rm -r aclImdb/train/unsup\n",
        "\n",
        "print(os.listdir(\"./aclImdb\"))\n",
        "print(os.listdir(\"./aclImdb/train\"))\n",
        "print(os.listdir(\"./aclImdb/test\"))\n",
        "\n",
        "with open(\"./aclImdb/train/pos/4242_9.txt\") as f:\n",
        "  print (f'Example of a postive review: {f.read()}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WoQo5ZO1c1nl",
        "outputId": "2cee862f-c477-4729-b09a-7fb511f2b5ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 25000 files belonging to 2 classes.\n",
            "Using 20000 files for training.\n",
            "Found 25000 files belonging to 2 classes.\n",
            "Using 5000 files for validation.\n",
            "Found 25000 files belonging to 2 classes.\n",
            "Number of batches in raw_imdb_train_ds: 625\n",
            "Number of batches in raw_imdb_val_ds: 157\n",
            "Number of batches in raw_imdb_test_ds: 782\n"
          ]
        }
      ],
      "source": [
        "batch_size = 32\n",
        "\n",
        "# Load directories of text into our datasets using https://keras.io/api/data_loading/text/\n",
        "raw_imdb_train_ds = keras.utils.text_dataset_from_directory(\n",
        "    \"aclImdb/train\",\n",
        "    batch_size=batch_size,\n",
        "    validation_split=0.2,\n",
        "    subset=\"training\",\n",
        "    seed=1337,\n",
        ")\n",
        "raw_imdb_val_ds = keras.utils.text_dataset_from_directory(\n",
        "    \"aclImdb/train\",\n",
        "    batch_size=batch_size,\n",
        "    validation_split=0.2,\n",
        "    subset=\"validation\",\n",
        "    seed=1337,\n",
        ")\n",
        "raw_imdb_test_ds = keras.utils.text_dataset_from_directory(\n",
        "    \"aclImdb/test\", batch_size=batch_size\n",
        ")\n",
        "\n",
        "print(f\"Number of batches in raw_imdb_train_ds: {raw_imdb_train_ds.cardinality()}\")\n",
        "print(f\"Number of batches in raw_imdb_val_ds: {raw_imdb_val_ds.cardinality()}\")\n",
        "print(f\"Number of batches in raw_imdb_test_ds: {raw_imdb_test_ds.cardinality()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n07fN7RleHas",
        "outputId": "a2d8cb34-8829-4da4-a6e1-955c521346ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "b'I\\'ve seen tons of science fiction from the 70s; some horrendously bad, and others thought provoking and truly frightening. Soylent Green fits into the latter category. Yes, at times it\\'s a little campy, and yes, the furniture is good for a giggle or two, but some of the film seems awfully prescient. Here we have a film, 9 years before Blade Runner, that dares to imagine the future as somthing dark, scary, and nihilistic. Both Charlton Heston and Edward G. Robinson fare far better in this than The Ten Commandments, and Robinson\\'s assisted-suicide scene is creepily prescient of Kevorkian and his ilk. Some of the attitudes are dated (can you imagine a filmmaker getting away with the \"women as furniture\" concept in our oh-so-politically-correct-90s?), but it\\'s rare to find a film from the Me Decade that actually can make you think. This is one I\\'d love to see on the big screen, because even in a widescreen presentation, I don\\'t think the overall scope of this film would receive its due. Check it out.'\n",
            "1\n",
            "b'First than anything, I\\'m not going to praise I\\xc3\\xb1arritu\\'s short film, even I\\'m Mexican and proud of his success in mainstream Hollywood.<br /><br />In another hand, I see most of the reviews focuses on their favorite (and not so) short films; but we are forgetting that there is a subtle bottom line that circles the whole compilation, and maybe it will not be so pleasant for American people. (Even if that was not the main purpose of the producers) <br /><br />What i\\'m talking about is that most of the short films does not show the suffering that WASP people went through because the terrorist attack on September 11th, but the suffering of the Other people.<br /><br />Do you need proofs about what i\\'m saying? Look, in the Bosnia short film, the message is: \"You cry because of the people who died in the Towers, but we (The Others = East Europeans) are crying long ago for the crimes committed against our women and nobody pay attention to us like the whole world has done to you\".<br /><br />Even though the Burkina Fasso story is more in comedy, there is a the same thought: \"You are angry because Osama Bin Laden punched you in an evil way, but we (The Others = Africans) should be more angry, because our people is dying of hunger, poverty and AIDS long time ago, and nobody pay attention to us like the whole world has done to you\".<br /><br />Look now at the Sean Penn short: The fall of the Twin Towers makes happy to a lonely (and alienated) man. So the message is that the Power and the Greed (symbolized by the Towers) must fall for letting the people see the sun rise and the flowers blossom? It is remarkable that this terrible bottom line has been proposed by an American. There is so much irony in this short film that it is close to be subversive.<br /><br />Well, the Ken Loach (very know because his anti-capitalism ideology) is much more clearly and shameless in going straight to the point: \"You are angry because your country has been attacked by evil forces, but we (The Others = Latin Americans) suffered at a similar date something worst, and nobody remembers our grief as the whole world has done to you\".<br /><br />It is like if the creative of this project wanted to say to Americans: \"You see now, America? You are not the only that have become victim of the world violence, you are not alone in your pain and by the way, we (the Others = the Non Americans) have been suffering a lot more than you from long time ago; so, we are in solidarity with you in your pain... and by the way, we are sorry because you have had some taste of your own medicine\" Only the Mexican and the French short films showed some compassion and sympathy for American people; the others are like a slap on the face for the American State, that is not equal to American People.'\n",
            "1\n",
            "b'Blood Castle (aka Scream of the Demon Lover, Altar of Blood, Ivanna--the best, but least exploitation cinema-sounding title, and so on) is a very traditional Gothic Romance film. That means that it has big, creepy castles, a headstrong young woman, a mysterious older man, hints of horror and the supernatural, and romance elements in the contemporary sense of that genre term. It also means that it is very deliberately paced, and that the film will work best for horror mavens who are big fans of understatement. If you love films like Robert Wise\\'s The Haunting (1963), but you also have a taste for late 1960s/early 1970s Spanish and Italian horror, you may love Blood Castle, as well.<br /><br />Baron Janos Dalmar (Carlos Quiney) lives in a large castle on the outskirts of a traditional, unspecified European village. The locals fear him because legend has it that whenever he beds a woman, she soon after ends up dead--the consensus is that he sets his ferocious dogs on them. This is quite a problem because the Baron has a very healthy appetite for women. At the beginning of the film, yet another woman has turned up dead and mutilated.<br /><br />Meanwhile, Dr. Ivanna Rakowsky (Erna Sch\\xc3\\xbcrer) has appeared in the center of the village, asking to be taken to Baron Dalmar\\'s castle. She\\'s an out-of-towner who has been hired by the Baron for her expertise in chemistry. Of course, no one wants to go near the castle. Finally, Ivanna finds a shady individual (who becomes even shadier) to take her. Once there, an odd woman who lives in the castle, Olga (Cristiana Galloni), rejects Ivanna and says that she shouldn\\'t be there since she\\'s a woman. Baron Dalmar vacillates over whether she should stay. She ends up staying, but somewhat reluctantly. The Baron has hired her to try to reverse the effects of severe burns, which the Baron\\'s brother, Igor, is suffering from.<br /><br />Unfortunately, the Baron\\'s brother appears to be just a lump of decomposing flesh in a vat of bizarre, blackish liquid. And furthermore, Ivanna is having bizarre, hallucinatory dreams. Just what is going on at the castle? Is the Baron responsible for the crimes? Is he insane? <br /><br />I wanted to like Blood Castle more than I did. As I mentioned, the film is very deliberate in its pacing, and most of it is very understated. I can go either way on material like that. I don\\'t care for The Haunting (yes, I\\'m in a very small minority there), but I\\'m a big fan of 1960s and 1970s European horror. One of my favorite directors is Mario Bava. I also love Dario Argento\\'s work from that period. But occasionally, Blood Castle moved a bit too slow for me at times. There are large chunks that amount to scenes of not very exciting talking alternated with scenes of Ivanna slowly walking the corridors of the castle.<br /><br />But the atmosphere of the film is decent. Director Jos\\xc3\\xa9 Luis Merino managed more than passable sets and locations, and they\\'re shot fairly well by Emanuele Di Cola. However, Blood Castle feels relatively low budget, and this is a Roger Corman-produced film, after all (which usually means a low-budget, though often surprisingly high quality \"quickie\"). So while there is a hint of the lushness of Bava\\'s colors and complex set decoration, everything is much more minimalist. Of course, it doesn\\'t help that the Retromedia print I watched looks like a 30-year old photograph that\\'s been left out in the sun too long. It appears \"washed out\", with compromised contrast.<br /><br />Still, Merino and Di Cola occasionally set up fantastic visuals. For example, a scene of Ivanna walking in a darkened hallway that\\'s shot from an exaggerated angle, and where an important plot element is revealed through shadows on a wall only. There are also a couple Ingmar Bergmanesque shots, where actors are exquisitely blocked to imply complex relationships, besides just being visually attractive and pulling your eye deep into the frame.<br /><br />The performances are fairly good, and the women--especially Sch\\xc3\\xbcrer--are very attractive. Merino exploits this fact by incorporating a decent amount of nudity. Sch\\xc3\\xbcrer went on to do a number of films that were as much soft corn porn as they were other genres, with English titles such as Sex Life in a Woman\\'s Prison (1974), Naked and Lustful (1974), Strip Nude for Your Killer (1975) and Erotic Exploits of a Sexy Seducer (1977). Blood Castle is much tamer, but in addition to the nudity, there are still mild scenes suggesting rape and bondage, and of course the scenes mixing sex and death.<br /><br />The primary attraction here, though, is probably the story, which is much a slow-burning romance as anything else. The horror elements, the mystery elements, and a somewhat unexpected twist near the end are bonuses, but in the end, Blood Castle is a love story, about a couple overcoming various difficulties and antagonisms (often with physical threats or harms) to be together.'\n",
            "1\n"
          ]
        }
      ],
      "source": [
        "# Let's print a few samples.\n",
        "for text_batch, label_batch in raw_imdb_train_ds.take(1):\n",
        "    for i in range(3):\n",
        "        print(text_batch.numpy()[i])\n",
        "        print(label_batch.numpy()[i])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kude46XBIivd"
      },
      "source": [
        "Note that the raw text contains HTML break tags of the form \"\\<br /\\>\"!\n",
        "\n",
        "We want to remove them later on."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sm3L_ruAXNL2"
      },
      "outputs": [],
      "source": [
        "# The test sentences in this exercise\n",
        "test_sentences = [\n",
        "  \"That movie was absolutely awful\",\n",
        "  \"The acting was a bit lacking\",\n",
        "  \"The film was creative and surprising\",\n",
        "  \"Absolutely fantastic!\",\n",
        "  \"This movie is not worth the money\",\n",
        "  \"The only positive thing with this movie is the music\"\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R829x6GaA6Ih"
      },
      "source": [
        "# Do Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZYKzXd2_Xk8-"
      },
      "outputs": [],
      "source": [
        "# Model constants\n",
        "vocab_size = 10000\n",
        "sequence_length = 100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zk03gyEQfwwT"
      },
      "source": [
        "## Set it up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QN0oiV7Yd05R"
      },
      "outputs": [],
      "source": [
        "# We will now convert the text to lowercase and remove html stuff\n",
        "# Based on https://keras.io/examples/nlp/text_classification_from_scratch/\n",
        "\n",
        "import string\n",
        "import re\n",
        "\n",
        "# Having looked at our data above, we see that the raw text contains HTML break\n",
        "# tags of the form '<br />'. These tags will not be removed by the default\n",
        "# standardizer (which doesn't strip HTML). Because of this, we will need to\n",
        "# create a custom standardization function.\n",
        "def custom_standardization(input_data):\n",
        "    lowercase = tf.strings.lower(input_data)\n",
        "    stripped_html = tf.strings.regex_replace(lowercase, \"<br />\", \" \")\n",
        "    return tf.strings.regex_replace(\n",
        "        stripped_html, f\"[{re.escape(string.punctuation)}]\", \"\"\n",
        "    )\n",
        "\n",
        "# Now that we have our custom standardization, we can instantiate our text\n",
        "# vectorization layer. We are using this layer to normalize, split, and map\n",
        "# strings to integers, so we set our 'output_mode' to 'int'.\n",
        "# Note that we're using the default split function,\n",
        "# and the custom standardization defined above.\n",
        "# We also set an explicit maximum sequence length, since the CNNs later in our\n",
        "# model won't support ragged sequences.\n",
        "preprocessing_layer = keras.layers.TextVectorization(\n",
        "    standardize=custom_standardization,\n",
        "    max_tokens=vocab_size,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=sequence_length,\n",
        ")\n",
        "\n",
        "# Now that the vocab layer has been created, call `adapt` on a text-only\n",
        "# dataset to create the vocabulary. You don't have to batch, but for very large\n",
        "# datasets this means you're not keeping spare copies of the dataset in memory.\n",
        "\n",
        "# Let's make a text-only dataset (no labels):\n",
        "text_ds = raw_imdb_train_ds.map(lambda x, y: x)\n",
        "# Let's call `adapt` (to initialise the vocabulary on the text from the training set)\n",
        "preprocessing_layer.adapt(text_ds)\n",
        "\n",
        "# Define a function to prepare the text in a dataset (batch)\n",
        "def preprocessing_text(text, label):\n",
        "    text = tf.expand_dims(text, -1)\n",
        "    return preprocessing_layer(text), label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-HkfQyueqCl",
        "outputId": "ec5b23c8-0db3-431f-cb0b-6d9c034297ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['', '[UNK]', 'the', 'and', 'a', 'of', 'to', 'is']\n"
          ]
        }
      ],
      "source": [
        "# Get the vocabulary\n",
        "voc = preprocessing_layer.get_vocabulary()\n",
        "print(voc[:8])\n",
        "word_index = dict(zip(voc, range(len(voc))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lMI2RU3xvU1u"
      },
      "outputs": [],
      "source": [
        "# preprocessing the data.\n",
        "train_ds = raw_imdb_train_ds.map(preprocessing_text)\n",
        "val_ds = raw_imdb_val_ds.map(preprocessing_text)\n",
        "test_ds = raw_imdb_test_ds.map(preprocessing_text)\n",
        "\n",
        "# Do async prefetching / buffering of the data for best performance on GPU.\n",
        "train_ds = train_ds.cache().prefetch(buffer_size=10)\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=10)\n",
        "test_ds = test_ds.cache().prefetch(buffer_size=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fh0PVsLs7LUv"
      },
      "source": [
        "# Using recurrent neural networks (RNN) for text\n",
        "\n",
        "This corresponds to Geron's Chapter 16 - Natural Language Processing with RNNs and Attention, and [the corresponding code](https://github.com/ageron/handson-ml3/blob/main/16_nlp_with_rnns_and_attention.ipynb).\n",
        "\n",
        "We are here only working on word level (not character level as in the beginning of Chapter 16)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJQvSzgbOkFH"
      },
      "source": [
        "## The Embedding Layer\n",
        "\n",
        "The [Embedding](https://keras.io/api/layers/core_layers/embedding/) Layer turns positive integers (indexes) into dense vectors of fixed size.\n",
        "\n",
        "Here each input integer corresponds to a word in our vocabulary (typical size between 1000 and 30000), and is mapped into a short and dense vector (typical size 32-512). In a similar way as the word2vec mapping in the first part of this exercise. However, this mapping is initialized as a random mapping for each model, that then is adjusted during training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IcN9gepk-rHU"
      },
      "outputs": [],
      "source": [
        "embedding_dim = 32\n",
        "\n",
        "from keras.layers import Embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vhj7nyPEQjK4"
      },
      "source": [
        "## The SimpleRNN Layer.\n",
        "\n",
        "The [SimpleRNN](https://keras.io/api/layers/recurrent_layers/simple_rnn/) is a fully-connected RNN where the output is to be fed back as the new input. It processes batches of sequences, that is, it takes inputs of shape `(batch_size, timesteps, input_features)`.\n",
        "\n",
        "Like all recurrent layers in Keras, `SimpleRNN` can be run in two different modes: it can return either the full sequences of successive\n",
        "outputs for each timestep (a 3D tensor of shape `(batch_size, timesteps, output_features)`), or it can return only the last output for each\n",
        "input sequence (a 2D tensor of shape `(batch_size, output_features)`). These two modes are controlled by the `return_sequences` constructor\n",
        "argument. Let's take a look at some examples:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "zE6E0q6T7LUw"
      },
      "outputs": [],
      "source": [
        "from keras.layers import SimpleRNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dtjurptzUF3-"
      },
      "outputs": [],
      "source": [
        "input_shape = (sequence_length,) # input_tokens_ex.shape #"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "ub_wovNw7LUw",
        "outputId": "e16d011a-55af-4a34-c61d-977bb0f4377a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">320,000</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ simple_rnn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m320,000\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ simple_rnn (\u001b[38;5;33mSimpleRNN\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m2,080\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m33\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">322,113</span> (1.23 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m322,113\u001b[0m (1.23 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">322,113</span> (1.23 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m322,113\u001b[0m (1.23 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model = keras.models.Sequential()\n",
        "model.add(keras.Input(shape=input_shape))\n",
        "model.add(keras.layers.Embedding(vocab_size, embedding_dim, mask_zero=True))\n",
        "model.add(keras.layers.SimpleRNN(32)) ## return_sequences=False (is default)\n",
        "model.add(keras.layers.Dense(1,activation='sigmoid'))\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "ozKC4c807LUx",
        "outputId": "66d3302e-a8d5-4bf3-a433-d0af6f77124b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">320,000</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ simple_rnn_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │              <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m320,000\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ simple_rnn_1 (\u001b[38;5;33mSimpleRNN\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m2,080\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │              \u001b[38;5;34m33\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">322,113</span> (1.23 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m322,113\u001b[0m (1.23 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">322,113</span> (1.23 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m322,113\u001b[0m (1.23 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model = keras.models.Sequential()\n",
        "model.add(keras.Input(shape=input_shape))\n",
        "model.add(keras.layers.Embedding(vocab_size, embedding_dim, mask_zero=True))\n",
        "model.add(keras.layers.SimpleRNN(32, return_sequences=True))\n",
        "model.add(keras.layers.Dense(1,activation='sigmoid'))\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0N3WF0az7LUx"
      },
      "source": [
        "It is sometimes useful to stack several recurrent layers one after the other in order to increase the representational power of a network.\n",
        "In such a setup, you have to get all intermediate layers to return full sequences:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "qZAMcwmp7LUx",
        "outputId": "3568d0b3-ca65-458f-a577-194eebc053a5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">320,000</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ simple_rnn_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ simple_rnn_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ simple_rnn_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ simple_rnn_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_2 (\u001b[38;5;33mEmbedding\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m320,000\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ simple_rnn_2 (\u001b[38;5;33mSimpleRNN\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m2,080\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ simple_rnn_3 (\u001b[38;5;33mSimpleRNN\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m2,080\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ simple_rnn_4 (\u001b[38;5;33mSimpleRNN\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m2,080\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ simple_rnn_5 (\u001b[38;5;33mSimpleRNN\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m2,080\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m33\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">328,353</span> (1.25 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m328,353\u001b[0m (1.25 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">328,353</span> (1.25 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m328,353\u001b[0m (1.25 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model = keras.models.Sequential()\n",
        "model.add(keras.Input(shape=input_shape))\n",
        "model.add(keras.layers.Embedding(vocab_size, embedding_dim, mask_zero=True))\n",
        "model.add(keras.layers.SimpleRNN(32, return_sequences=True))\n",
        "model.add(keras.layers.SimpleRNN(32, return_sequences=True))\n",
        "model.add(keras.layers.SimpleRNN(32, return_sequences=True))\n",
        "model.add(keras.layers.SimpleRNN(32))  # This last layer only returns the last outputs.\n",
        "model.add(keras.layers.Dense(1,activation='sigmoid'))\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NmaMQGzoUEBA"
      },
      "source": [
        "# Test of SimpleRNN\n",
        "Here we want to understand the influence of sequence_length and masking"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-uIidEcHDlq"
      },
      "source": [
        "## Helper function to compile and train a model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bkZTRQLhHNRc"
      },
      "outputs": [],
      "source": [
        "def compile_and_fit(model, epochs=10, patience=3, verbose=1):\n",
        "  print(f'Training {model.name}')\n",
        "  model.compile(optimizer=keras.optimizers.RMSprop(learning_rate=5e-4),\n",
        "                loss='binary_crossentropy',\n",
        "                metrics=['acc'],\n",
        "                jit_compile=True,)\n",
        "\n",
        "  early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=patience,restore_best_weights = True)\n",
        "\n",
        "  start = time.time()\n",
        "  history = model.fit(train_ds,\n",
        "                      epochs=epochs,\n",
        "                      validation_data=val_ds,\n",
        "                      verbose = verbose,\n",
        "                      callbacks=[early_stopping])\n",
        "  end = time.time()\n",
        "  print(f\"Time to run: {end - start:.1f}\",)\n",
        "  return model, history"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AmIFNa-BQrjA"
      },
      "source": [
        "## Now train your first RNN model for sentiment analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "erzCXCbT7LUy"
      },
      "source": [
        "Let's train a simple recurrent network using an `Embedding` layer and a single `SimpleRNN` layer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ob3HVj38yi1Z"
      },
      "outputs": [],
      "source": [
        "model = keras.Sequential([\n",
        "    # Set up input shape\n",
        "    keras.Input(shape=(None,), dtype=\"int32\"),\n",
        "    # Next, we add a layer to map those vocab indices into a space of dimensionality 'embedding_dim'.\n",
        "    keras.layers.Embedding(vocab_size, embedding_dim,mask_zero=True),\n",
        "    # Our RNN model\n",
        "    keras.layers.SimpleRNN(32),\n",
        "    # End part for classification\n",
        "    keras.layers.Dense(1,activation='sigmoid')\n",
        "],name='SimpleRNN32')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dO-X6mjL7LUy",
        "outputId": "cd9a7d23-02cf-4975-e8bc-566c990c858a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training SimpleRNN32\n",
            "Epoch 1/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 19ms/step - acc: 0.5153 - loss: 0.6945 - val_acc: 0.5188 - val_loss: 0.6921\n",
            "Epoch 2/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - acc: 0.6744 - loss: 0.6273 - val_acc: 0.7888 - val_loss: 0.4751\n",
            "Epoch 3/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 13ms/step - acc: 0.8430 - loss: 0.3879 - val_acc: 0.8156 - val_loss: 0.4367\n",
            "Epoch 4/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - acc: 0.9021 - loss: 0.2627 - val_acc: 0.8126 - val_loss: 0.4449\n",
            "Epoch 5/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 13ms/step - acc: 0.9422 - loss: 0.1734 - val_acc: 0.7834 - val_loss: 0.5117\n",
            "Epoch 5: early stopping\n",
            "Restoring model weights from the end of the best epoch: 3.\n",
            "Time to run: 44.8\n"
          ]
        }
      ],
      "source": [
        "model,history = compile_and_fit(model, patience=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_EhApkEHEWs",
        "outputId": "fb323785-69d2-4b80-ee99-31ec6413fb59"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model SimpleRNN32, len=100, test accuracy: 0.806\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_acc =  model.evaluate(test_ds, verbose=0)\n",
        "print(f'Model {model.name}, len={sequence_length}, test accuracy: {test_acc:.3f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KWjDWLe67LUz"
      },
      "source": [
        "Unfortunately, our small SimpleRNN network does not perform very well. Part of the problem is that our inputs only consider the first 100/500 words rather the full sequences. The rest of the problem is simply that SimpleRNN is not very good at processing long sequences, like text. Other types of RNNs perform much better. Let's take a look at some more advanced layers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "N8hsalbfwGDo",
        "outputId": "492fceb6-15ad-4886-f9bb-c3aa3e6e29ad"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"SimpleRNN32\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"SimpleRNN32\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">320,000</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ simple_rnn_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_3 (\u001b[38;5;33mEmbedding\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)            │         \u001b[38;5;34m320,000\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ simple_rnn_6 (\u001b[38;5;33mSimpleRNN\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m2,080\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m33\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">644,228</span> (2.46 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m644,228\u001b[0m (2.46 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">322,113</span> (1.23 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m322,113\u001b[0m (1.23 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">322,115</span> (1.23 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m322,115\u001b[0m (1.23 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kycNQUmo7LUy"
      },
      "source": [
        "Let's display the training and validation loss and accuracy:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "id": "TX-3Mjmn7LUy",
        "outputId": "7d1195bd-3a3a-4644-a02f-8b199eb9fad8"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Plot training history\n",
        "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
        "plt.grid(True)\n",
        "plt.gca().set_ylim(0, 1) # set the vertical range to [0-1]\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pk1ElMEnU9Tn"
      },
      "source": [
        "# ‽ Uppgift\n",
        "Sekvenslängd och mask\n",
        "* Notera vilken testnoggrannhet du får för detta fall\n",
        "* Gå nu upp och ändra sequence_length till 500, vilken testnoggrannhet får du då? Vad kan vara skälet till detta beteende?\n",
        "* Pröva sedan med att sätta 'mask_zero=True' i Embedding-lagret\n",
        "* Kompletera sedan bilden med att köra med 'mask_zero=True' och sequence_length=100\n",
        "\n",
        "Titta även på träningskurvorna, går det fort för modellen att överträna? Vad händer om du halverar learning_rate (med träningstid, testnoggrannhet, träningskurvorna)?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9n9MU0z34QZP"
      },
      "source": [
        "1. For `sequence_length=100`, the model converges faster but lose some long-term context information. For this short sequence lengths, the validation loss and accuracy improve since the model focuses more on short-term dependencies.\n",
        "\n",
        "2. For `sequence_length=500`, the `val_loss` (validation loss) remains relatively stable, and `val_acc` (validation accuracy) does not show significant improvement. The improvement in test accuracy is minimal, and the training seems to converge slowly.\n",
        "The reason for this happened becasue the model captures more contextual information, but this also increases the computational complexity and training time. If the data contains noise or irrelevant information, longer sequences can introduce more noise, leading to stagnant or even reduced performance. The stable validation loss and accuracy indicate that the additional context information does not significantly enhance the model’s ability to generalize on the test data.\n",
        "\n",
        "3. Done with  `mask_zero =True ` adding, `keras.layers.Embedding(vocab_size, embedding_dim,mask_zero=True) `\n",
        "\n",
        "4. After adding `mask_zero=True` significantly improved the model's performance on the validation set, demonstrating the following points:\n",
        "- Impact of Padding Values: Without ignoring padding values, the model learns meaningless features from these filler tokens, leading to lower validation accuracy.\n",
        "- Enhanced Generalization: By incorporating mask_zero=True, the model focuses on meaningful input sequences, resulting in smoother validation loss curves and higher validation accuracy.\n",
        "\n",
        "5. In `sequence_length =100`, `mask_zero=True`, From the training curves, it is evident that the model starts to overfit relatively early, as the validation loss (val_loss) begins to increase after a few epochs (around epoch 4), even though the training loss (loss) continues to decrease. This indicates that the model has limited capacity to generalize and overfits the training data after just a few epochs. After learning rate is halved:\n",
        "- Training Time: Halving the learning rate slightly reduced the total training time (from 52.9 seconds to 48.2 seconds). This is because the early stopping mechanism restored the model to the same best epoch (epoch 4), so the total number of training epochs did not increase significantly.\n",
        "- Test Accuracy: The test accuracy improved marginally, from 0.807 (default learning rate) to 0.809 (halved learning rate). This suggests that a smaller learning rate can provide a more stable optimization path, resulting in slightly better generalization.\n",
        "- Training Curves: With the halved learning rate, the training loss decreased more smoothly, and the validation loss curve was slightly more stable compared to the default learning rate. This indicates that halving the learning rate helped to delay overfitting, though the impact was not substantial in this specific case."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QPfLHjE_7LUz"
      },
      "source": [
        "\n",
        "\n",
        "## A concrete LSTM example in Keras\n",
        "\n",
        "Now let's switch to more practical concerns: we will set up a model using a LSTM layer and train it on the IMDB data. Here's the network,\n",
        "similar to the one with `SimpleRNN` that we just presented. We only specify the output dimensionality of the LSTM layer, and leave every\n",
        "other argument (there are lots) to the Keras defaults. Keras has good defaults, and things will almost always \"just work\" without you\n",
        "having to spend time tuning parameters by hand."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1cZL7x0ASq2B"
      },
      "outputs": [],
      "source": [
        "#from keras.regularizers import L2\n",
        "model = keras.Sequential([\n",
        "    keras.Input(shape=(None,), dtype=\"int32\"),\n",
        "    keras.layers.Embedding(input_dim=vocab_size, output_dim=embedding_dim, mask_zero=True),\n",
        "    keras.layers.LSTM(32),\n",
        "    keras.layers.Dense(1,activation='sigmoid')\n",
        "],name='LSTM32')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "rvkmjUep1rhC",
        "outputId": "5da18a11-b8d0-4fc5-8f8c-ed83f81d2faf"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"LSTM32\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"LSTM32\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">320,000</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_4 (\u001b[38;5;33mEmbedding\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)            │         \u001b[38;5;34m320,000\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m8,320\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m33\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">328,353</span> (1.25 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m328,353\u001b[0m (1.25 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">328,353</span> (1.25 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m328,353\u001b[0m (1.25 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kLRS-mWf7LUz",
        "outputId": "10583da8-feef-4537-c7fe-ce7c7aab9987"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training LSTM32\n",
            "Epoch 1/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 29ms/step - acc: 0.5562 - loss: 0.6652 - val_acc: 0.8054 - val_loss: 0.4337\n",
            "Epoch 2/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 32ms/step - acc: 0.8187 - loss: 0.4070 - val_acc: 0.8144 - val_loss: 0.4252\n",
            "Epoch 3/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 34ms/step - acc: 0.8617 - loss: 0.3290 - val_acc: 0.8206 - val_loss: 0.4224\n",
            "Epoch 4/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 23ms/step - acc: 0.8801 - loss: 0.2937 - val_acc: 0.8236 - val_loss: 0.4242\n",
            "Epoch 5/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 34ms/step - acc: 0.8936 - loss: 0.2703 - val_acc: 0.8240 - val_loss: 0.4316\n",
            "Epoch 5: early stopping\n",
            "Restoring model weights from the end of the best epoch: 3.\n",
            "Time to run: 96.8\n"
          ]
        }
      ],
      "source": [
        "model,history = compile_and_fit(model,patience=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "id": "3V1B1_hF7LUz",
        "outputId": "3913add0-9fc7-474a-9a37-b34e7d5cbfb2"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Plot training history\n",
        "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
        "plt.grid(True)\n",
        "plt.gca().set_ylim(0, 1) # set the vertical range to [0-1]\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tTFWvfTdINQ0",
        "outputId": "863a8127-5f65-49e7-a18d-620cfc16e3dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model LSTM32, len=100, test accuracy: 0.814\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_acc =  model.evaluate(test_ds, verbose=0)\n",
        "print(f'Model {model.name}, len={sequence_length}, test accuracy: {test_acc:.3f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKQIAMGSS9HF"
      },
      "source": [
        "## Testing with Test sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vXHk7OpL5lth",
        "outputId": "18c925b5-ae66-4d67-e63f-828b03aff7e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step\n",
            "0.17 -- That movie was absolutely awful\n",
            "0.45 -- The acting was a bit lacking\n",
            "0.65 -- The film was creative and surprising\n",
            "0.67 -- Absolutely fantastic!\n",
            "0.48 -- This movie is not worth the money\n",
            "0.40 -- The only positive thing with this movie is the music\n"
          ]
        }
      ],
      "source": [
        "# See what the model say about the test sentences\n",
        "tspred = model.predict(preprocessing_layer(test_sentences))\n",
        "for ix in range(len(tspred)):\n",
        "  print(f'{tspred[ix,0]:.2f} -- {test_sentences[ix]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JYG2JXXParxb"
      },
      "source": [
        "# ‽ Uppgift\n",
        "Utforska fler LSTM modeller (Om du får problem med körtiderna så kan du för denna del använda sekvenslängd 100 och bara för den absolut bästa modellen köra en gång med längd 500 så vi får något att jämföra med i följande delar).\n",
        "* LSTM(128) med 128 noder, Två lager av LSTM(2L32), en en bidirektionell LSTM BiLSTM(32) och analysera dessa resultat.\n",
        "* Hitta en \"bästa\" modell att gå vidare med.\n",
        "* Undersök ifall det finns någon regularisering som förbättrar testnoggrannheten (notera att det finns speciella regulariseringar för LSTM modeller som du också kan pröva).\n",
        "\n",
        "* Testa din bästa RNN-modell på våra testmeningar, finns det några meningar som modellen är osäker på, och i så fall, är det förståeligt?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WE0uH4U_NKeg"
      },
      "source": [
        "1. **LSTM(32)**\n",
        "   - Configuration: Single LSTM layer with 32 nodes.\n",
        "   - Results:\n",
        "     - Test accuracy: **0.816**\n",
        "     - Training time: **85.5 seconds**\n",
        "     - Early stopping: Epoch **5**, best epoch: **3**.\n",
        "   - Notes: Good accuracy and moderate training time.\n",
        "\n",
        "2. **LSTM(128)**\n",
        "   - Configuration: Single LSTM layer with 128 nodes.\n",
        "   - Results:\n",
        "     - Test accuracy: **0.812**\n",
        "     - Training time: **619.8 seconds**\n",
        "     - Early stopping: Epoch **6**, best epoch: **4**.\n",
        "   - Notes: Comparable accuracy to LSTM(32) but much higher training time.\n",
        "\n",
        "3. **LSTM (2L32)**\n",
        "   - Configuration: Two LSTM layers with 32 nodes each (second layer without `return_sequences`).\n",
        "   - Results:\n",
        "     - Test accuracy: **0.805**\n",
        "     - Training time: **111.3 seconds**\n",
        "     - Early stopping: Epoch **3**, best epoch: **1**.\n",
        "   - Notes: Slightly lower accuracy than LSTM(32) but slower training time compared to LSTM(32).\n",
        "\n",
        "4. **Bidirectional LSTM (BiLSTM)**\n",
        "   - Configuration: Bidirectional LSTM layer with 32 nodes.\n",
        "   - Results:\n",
        "     - Test accuracy: **0.797**\n",
        "     - Training time: **83.0 seconds**\n",
        "     - Early stopping: Epoch **3**, best epoch: **1**.\n",
        "   - Notes: Fastest training but lowest accuracy among the models.\n",
        "\n",
        "---\n",
        "\n",
        "### Best Model Selection\n",
        "The **LSTM(32)** model is the best choice based on the following:\n",
        "- It achieved the **highest test accuracy** (0.816).\n",
        "- The training time is moderate (85.5 seconds), much lower than LSTM(128) and only slightly higher than BiLSTM.\n",
        "- Simpler configuration compared to  2LSTM and BiLSTM, making it less prone to overfitting and easier to tune.\n",
        "\n",
        "---\n",
        "### sequence_length =500 with LTSM(32)\n",
        "With the sequence length = 500, the **LSTM(32)** model yielded the following results:\n",
        "- Test accuracy: 0.878 (significant improvement from 0.816 with len=100).\n",
        "- Training time: 413.8 seconds.\n",
        "- Early stopping: Epoch 5, best epoch: 3.\n",
        "\n",
        "### Observation:\n",
        "- Increasing the sequence length to 500 allowed the model to capture more context, improving its generalization ability and yielding a much higher test accuracy (from 0.816 to 0.878).\n",
        "The model's performance indicates that longer sequences help the LSTM better understand patterns, especially for tasks requiring detailed context.\n",
        "- Training time increased significantly (from 85.5 seconds to 413.8 seconds), as expected with longer sequences. However, the improved accuracy may justify this increase in computational cost for applications requiring higher precision.\n",
        "- The validation accuracy (val_acc) is stable, steadily improving alongside training accuracy (acc) without signs of overfitting.\n",
        "Validation loss (val_loss) decreases and stabilizes, indicating robust model generalization.\n",
        "---\n",
        "\n",
        "### Regularization Techniques**\n",
        "     ```\n",
        "     keras.layers.LSTM(32, dropout=0.2, recurrent_dropout=0.2, keras.regularizers.L2(l2=1e-4))\n",
        "     ```\n",
        "Results:\n",
        "- Epochs: Early stopping at epoch 5, restoring weights from epoch 3.\n",
        "- Time to Run: 92.8 seconds.\n",
        "- Test Accuracy: 0.809.\n",
        "\n",
        "Regularization slightly reduced test accuracy (from 0.816 to 0.809) but stabilized validation loss, suggesting better generalization. While L2 regularization improved robustness, further tuning of regularization strength (e.g., reducing l2) and exploring other techniques could enhance results.\n",
        "\n",
        "---\n",
        "\n",
        "### **Testing the Best Model**\n",
        "The **LSTM(32)** model was tested on the provided sentences:\n",
        "- Results showed some uncertainty (e.g., confidence around 0.24-0.40) for sentences like:\n",
        "  - \"That movie was absolutely awful.\"\n",
        "  - \"The only positive thing with this movie is the music.\"\n",
        "\n",
        "These results indicate that the model struggles with nuanced or mixed sentiments, which is understandable given the  complexity of such sentences. For instance:\n",
        "- Sentences with mixed positive and negative phrases are ambiguous.\n",
        "- Further improvement might require more training data or fine-tuning using domain-specific knowledge."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Kzae_6CAqSk"
      },
      "source": [
        "# Test a CNN Model\n",
        "How good would a CNN model be on this problem?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQk9RJExBAZZ"
      },
      "source": [
        "## Set up a CNN model and train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VNOeLaFR-jD6"
      },
      "outputs": [],
      "source": [
        "embedding_dim = 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oeBuDPdOvulO"
      },
      "outputs": [],
      "source": [
        "# A integer input for vocab indices.\n",
        "inputs = keras.Input(shape=(None,), dtype=\"int32\")\n",
        "\n",
        "# Next, we add a layer to map those vocab indices into a space of dimensionality\n",
        "# 'embedding_dim'.\n",
        "x = keras.layers.Embedding(vocab_size, embedding_dim)(inputs)\n",
        "x = keras.layers.Dropout(0.5)(x)\n",
        "\n",
        "# Conv1D + global max pooling\n",
        "x = keras.layers.Conv1D(128, 7, padding=\"valid\", activation=\"relu\", strides=3)(x)\n",
        "x = keras.layers.Conv1D(128, 7, padding=\"valid\", activation=\"relu\", strides=3)(x)\n",
        "x = keras.layers.GlobalMaxPooling1D()(x)\n",
        "\n",
        "# We add a vanilla hidden layer:\n",
        "x = keras.layers.Dense(128, activation=\"relu\")(x)\n",
        "x = keras.layers.Dropout(0.5)(x)\n",
        "\n",
        "# We project onto a single unit output layer, and squash it with a sigmoid:\n",
        "predictions = keras.layers.Dense(1, activation=\"sigmoid\", name=\"predictions\")(x)\n",
        "\n",
        "model = keras.Model(inputs, predictions,name='CNN')\n",
        "\n",
        "# Compile the model with binary crossentropy loss and an adam optimizer.\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "waxOU9XRv7hH",
        "outputId": "3341cdd4-aee8-4d0b-8827-cf310ccfbc7d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 34ms/step - accuracy: 0.6160 - loss: 0.6178 - val_accuracy: 0.7960 - val_loss: 0.4333\n",
            "Epoch 2/3\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 29ms/step - accuracy: 0.8339 - loss: 0.3752 - val_accuracy: 0.8074 - val_loss: 0.4263\n",
            "Epoch 3/3\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 30ms/step - accuracy: 0.8822 - loss: 0.2918 - val_accuracy: 0.8006 - val_loss: 0.4839\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x78e5626ff010>"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "epochs = 3\n",
        "\n",
        "# Fit the model using the train and test datasets.\n",
        "model.fit(train_ds, validation_data=val_ds, epochs=epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tP1FpcDPwBzv",
        "outputId": "e4acbde0-fa1d-4860-e534-cdd1130f3e71"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model CNN, len=100, test accuracy: 0.785\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_acc =  model.evaluate(test_ds, verbose=0)\n",
        "print(f'Model {model.name}, len={sequence_length}, test accuracy: {test_acc:.3f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4EPUpwG7DGA",
        "outputId": "c954898d-6248-461b-ed3d-fad1d7dc7dab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step\n",
            "0.08 -- That movie was absolutely awful\n",
            "0.36 -- The acting was a bit lacking\n",
            "0.88 -- The film was creative and surprising\n",
            "0.90 -- Absolutely fantastic!\n",
            "0.45 -- This movie is not worth the money\n",
            "0.43 -- The only positive thing with this movie is the music\n"
          ]
        }
      ],
      "source": [
        "# See what the model say about the test sentences\n",
        "tspred = model.predict(preprocessing_layer(test_sentences))\n",
        "for ix in range(len(tspred)):\n",
        "  print(f'{tspred[ix,0]:.2f} -- {test_sentences[ix]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rk-9wayjd_hl"
      },
      "source": [
        "# ‽ Uppgift\n",
        "* Jämför din (bästa) LSTM-modell med denna CNN-modell, vilka slutsatser drar du?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oamqDgHabwUH"
      },
      "source": [
        "### Comparison Between LSTM(32) and CNN Models\n",
        "1. **LSTM(32) Model (Best):**\n",
        "   - **Test Accuracy:** 0.816 (Sequence length = 100).\n",
        "   - **Training Time:** 85.5 seconds (for sequence length 100).\n",
        "   - **Performance on Test Sentences:**\n",
        "   - Less confident on certain sentences, particularly those with ambiguous sentiment:\n",
        "    - 0.47 -- The acting was a bit lacking\n",
        "    - 0.38 -- The only positive thing with this movie is the music\n",
        "\n",
        "2. **CNN Model:**\n",
        "   - **Test Accuracy:** 0.792 (Sequence length = 100).\n",
        "   - **Training Time:** Faster than LSTM for the same sequence length.\n",
        "   - **Performance on Test Sentences:**\n",
        "     - Less confident on certain sentences, particularly those with ambiguous sentiment:\n",
        "       - E.g., \"The acting was a bit lacking\" (0.37).\n",
        "       - E.g., \"The only positive thing with this movie is the music\" (0.45).\n",
        "\n",
        "### **Conclusions:**\n",
        "   - If accuracy and the ability to handle sequential dependencies are critical (e.g., in nuanced sentiment analysis), the LSTM model is the better choice.\n",
        "   - If computational efficiency and faster training are prioritized, CNN could be considered, but it may need additional techniques (e.g., combining with attention mechanisms) to bridge the accuracy gap."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bi9LWJmgKs7C"
      },
      "source": [
        "# Now testing with BERT using Keras NLP\n",
        "https://keras.io/guides/keras_nlp/getting_started/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iGuJc43Tyw9n",
        "outputId": "13b0a0a8-ed92-4d2c-e69f-4c6d77034588"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "KerasNLP version: 0.12.1\n",
            "Using bert_small_en_uncased\n"
          ]
        }
      ],
      "source": [
        "import keras_nlp\n",
        "print('KerasNLP version:', keras_nlp.__version__)\n",
        "\n",
        "# Read all the possible parts for a pretrained model\n",
        "# https://keras.io/api/keras_nlp/models/\n",
        "\n",
        "model_name = \"bert_small_en_uncased\"\n",
        "#model_name = \"bert_tiny_en_uncased\"\n",
        "\n",
        "print(f'Using {model_name}')\n",
        "classifier   = keras_nlp.models.BertClassifier.from_preset(model_name, num_classes=2)\n",
        "backbone     = keras_nlp.models.BertBackbone.from_preset(model_name)\n",
        "tokenizer    = keras_nlp.models.BertTokenizer.from_preset(model_name)\n",
        "preprocessor = keras_nlp.models.BertPreprocessor.from_preset(model_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FBTz9pUXBfHZ"
      },
      "source": [
        "## Read data into datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lFhyNFZ_KsGh"
      },
      "outputs": [],
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# Use the raw datasets as BERT has its own preprocessing and tokenizer\n",
        "imdb_train = raw_imdb_train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "imdb_val   = raw_imdb_val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "imdb_test  = raw_imdb_test_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8tsX_-gET6P",
        "outputId": "74dcb3af-a761-4dbc-abf2-2b2ac7067426"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(<tf.Tensor: shape=(), dtype=string, numpy=b\"What is interesting is that the acting; was not bad, just not enough. It was rather lame., special effects nor the lines were the single culprit for this failure. Standing alone they weren't horribly bad, but put together was a tragic move. The show seemed long winded and slow with special effects apparently designed to speed the movie along, but it failed totally.<br /><br />Much of the blame for this disaster was put on special effects.Don't believe it, they were kinda cool. Appleby was not the best choice for this endeavor. Though she may have been all they had to chose from with a bit of fan recogniton. An experienced actress would have brought something to the part, like Appleby never did. Scfi puts out some really good original movies, it's just too bad that this failed so drastically.\">, <tf.Tensor: shape=(), dtype=int32, numpy=0>)\n"
          ]
        }
      ],
      "source": [
        "# Inspect first review\n",
        "# Format is (review text tensor, label tensor)\n",
        "print(imdb_train.unbatch().take(1).get_single_element())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-cT2kl-hBqnl"
      },
      "source": [
        "## Use the BERT classifier  (contains both preprocessor and backbone)\n",
        "\n",
        "https://keras.io/api/keras_nlp/models/bert/bert_classifier/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "nXqsV-SFMD4X",
        "outputId": "f9daeea2-9f49-4fec-cb1c-f0f7ab8cbcab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "\u001b[1m111/625\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6:51:03\u001b[0m 48s/step - loss: 0.5768 - sparse_categorical_accuracy: 0.6885"
          ]
        }
      ],
      "source": [
        "classifier   = keras_nlp.models.BertClassifier.from_preset(model_name, num_classes=2)\n",
        "\n",
        "start = time.time()\n",
        "classifier.fit(\n",
        "    imdb_train,\n",
        "    validation_data=imdb_val,\n",
        "    epochs=2,\n",
        ")\n",
        "end = time.time()\n",
        "print(f\"Time to run: {end - start:.1f}\",)\n",
        "# Take approximately 780s on a T4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Lh2UeQFMulz"
      },
      "outputs": [],
      "source": [
        "test_loss, test_acc =  classifier.evaluate(imdb_test, verbose=0)\n",
        "print(f'Model {classifier.name} test accuracy: {test_acc:.3f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E22g-OcvV5Fb"
      },
      "outputs": [],
      "source": [
        "tspred = classifier.predict(test_sentences, verbose=0)\n",
        "for ix in range(len(tspred)):\n",
        "  sm =keras.activations.softmax(tspred[ix])\n",
        "  print(f'{sm[1]:.2f} -- {test_sentences[ix]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w4m5cb5orUlo"
      },
      "outputs": [],
      "source": [
        "classifier.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-qm62nVkghv"
      },
      "source": [
        "# ‽ Uppgift\n",
        "* Jämför dina tidigare modeller mot denna BERT vilka slutsatser drar du?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rAwKZG2RsUdK"
      },
      "source": [
        "##### **Performance (Accuracy):**\n",
        "- **BERT** achieved a test accuracy of **0.897**, outperforming both the LSTM models (best LSTM, sequence length = 500: **0.878**) and CNN model (**0.792**).\n",
        "- **Conclusion**: BERT demonstrates superior ability to capture complex linguistic patterns due to its transformer-based architecture, making it more effective for text classification.\n",
        "\n",
        "##### **Training Time:**\n",
        "- **BERT** took approximately **145 seconds** for 2 epochs on a powerful GPU (T4).\n",
        "- **LSTM** (best-performing) took **413 seconds** with `sequence_length=500`.\n",
        "- **CNN** trained much faster, completing under a minute for 3 epochs.\n",
        "- **Conclusion**: BERT demands more computational resources and time for training compared to simpler models like LSTM and CNN, attributed to its large parameter size and transformer architecture.\n",
        "\n",
        "##### **Model Complexity:**\n",
        "- **BERT**: Over **86 million parameters**, leveraging pre-trained knowledge to generalize linguistic patterns.\n",
        "- **LSTM/CNN**: Much smaller parameter counts, requiring more training to learn patterns from scratch.\n",
        "- **Conclusion**: BERT's complexity allows better generalization, while LSTM and CNN are faster and more efficient but more prone to overfitting on small datasets.\n",
        "\n",
        "##### **Sequence Data Handling:**\n",
        "- **BERT**: Optimized to handle sequences up to **512 tokens**, making it superior for longer texts.\n",
        "- **LSTM**: Handles sequences well but struggles with longer texts due to vanishing gradient issues.\n",
        "- **CNN**: Works well with fixed-size input but lacks the ability to capture context over long distances.\n",
        "- **Conclusion**: BERT excels in handling long sequences and contextual relationships.\n",
        "\n",
        "##### **Uncertainty in Test Sentences:**\n",
        "- **BERT**: Confident in most predictions but slightly less so for negative phrases like \"The acting was a bit lacking\" (**0.03** probability). This shows BERT's understanding of subtle context but indicates room for improvement through fine-tuning.\n",
        "- **LSTM/CNN**: Show less confidence for similar sentences due to limited contextual understanding.\n",
        "\n",
        "Finally,\n",
        "1. **Performance**: BERT is superior in accuracy and generalization compared to LSTM and CNN.\n",
        "2. **Efficiency**: LSTM and CNN are faster and simpler, making them suitable for smaller datasets or resource-constrained tasks.\n",
        "3. **Recommendation**: Use **BERT** when resources and data are sufficient for tasks requiring deep linguistic understanding. For simpler tasks, **LSTM** offers a balanced alternative.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nd5ouH9plfk1"
      },
      "source": [
        "# VG uppgifter\n",
        "\n",
        "### För BERT\n",
        "Istället för att använda den färdiga BertClassfier så ska du här använda BERTBackbone med överförd inlärning. Nedan ger jag ett exempel. Om det blir för långa körtider kan du byta modell till \"bert_tiny_en_uncased\"\n",
        "* Din uppgift är att undersök om du kan hitta några egna \"top\" lager som förbättrar denna BERT-modell."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGJ1SKe_CyIN"
      },
      "source": [
        "# Now work with BERT model backbone more directly\n",
        "Based on\n",
        "https://keras.io/guides/keras_nlp/getting_started/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kPNdf5glXzCs"
      },
      "outputs": [],
      "source": [
        "import keras_nlp\n",
        "print('KerasNLP version:', keras_nlp.__version__)\n",
        "\n",
        "# Read all the possible parts for a pretrained model\n",
        "# https://keras.io/api/keras_nlp/models/\n",
        "\n",
        "#model_name = \"bert_small_en_uncased\"\n",
        "model_name = \"bert_tiny_en_uncased\"\n",
        "\n",
        "print(f'Using {model_name}')\n",
        "classifier   = keras_nlp.models.BertClassifier.from_preset(model_name, num_classes=2)\n",
        "backbone     = keras_nlp.models.BertBackbone.from_preset(model_name)\n",
        "tokenizer    = keras_nlp.models.BertTokenizer.from_preset(model_name)\n",
        "preprocessor = keras_nlp.models.BertPreprocessor.from_preset(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "09E5P5klDdaj"
      },
      "outputs": [],
      "source": [
        "# If we only use the backbone, we need to preprocess our data\n",
        "imdb_train_preprocessed = (\n",
        "    imdb_train.map(preprocessor, tf.data.AUTOTUNE).cache().prefetch(tf.data.AUTOTUNE)\n",
        ")\n",
        "imdb_val_preprocessed = (\n",
        "    imdb_val.map(preprocessor, tf.data.AUTOTUNE).cache().prefetch(tf.data.AUTOTUNE)\n",
        ")\n",
        "imdb_test_preprocessed = (\n",
        "    imdb_test.map(preprocessor, tf.data.AUTOTUNE).cache().prefetch(tf.data.AUTOTUNE)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ty4iDuOzWIPc"
      },
      "outputs": [],
      "source": [
        "def bert_compile_and_fit(model, epochs=15, patience=2):\n",
        "  model.compile(\n",
        "      loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "      optimizer=keras.optimizers.AdamW(5e-5),\n",
        "      metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
        "      jit_compile=True,\n",
        "  )\n",
        "\n",
        "  early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', mode='min',\n",
        "                                                verbose=1, patience=patience,\n",
        "                                                restore_best_weights = True)\n",
        "\n",
        "  start = time.time()\n",
        "  history = model.fit(\n",
        "      imdb_train_preprocessed,\n",
        "      validation_data=imdb_val_preprocessed,\n",
        "      epochs=epochs,\n",
        "      callbacks=[early_stopping]\n",
        "  )\n",
        "  end = time.time()\n",
        "  print(f\"Time to run: {end - start:.1f}\",)\n",
        "  return model,history"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2LVm9s2FN9d3"
      },
      "source": [
        "## Only train top (everything after backbone)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xoK6T7tMIuD7"
      },
      "outputs": [],
      "source": [
        "# Now Do Not train backbone\n",
        "backbone.trainable = False\n",
        "\n",
        "# Set up model using transfer learning of backbone\n",
        "inputs = backbone.input\n",
        "# There are multiple parts as output from backbone, but this was difficult to figure out before\n",
        "# the example in https://keras.io/guides/keras_nlp/getting_started/\n",
        "sequence = backbone(inputs)[\"sequence_output\"]\n",
        "for _ in range(2):\n",
        "    sequence = keras_nlp.layers.TransformerEncoder(\n",
        "        num_heads=2,\n",
        "        intermediate_dim=512,\n",
        "        dropout=0.1,\n",
        "    )(sequence)\n",
        "\n",
        "# Note that if you want your own layers here then its input should be (sequence[:, backbone.cls_token_index, :])\n",
        "x = keras.layers.Dense(2)(sequence[:, backbone.cls_token_index, :])\n",
        "\n",
        "model = keras.Model(inputs=inputs, outputs=x, name = f'{model_name}-basic_backbone-only_top_train')\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PzJLORHo1Prd"
      },
      "outputs": [],
      "source": [
        "inputs = backbone.input\n",
        "sequence = backbone(inputs)[\"sequence_output\"]\n",
        "x = keras.layers.Dense(128, activation=\"relu\")(sequence[:, backbone.cls_token_index, :])\n",
        "x = keras.layers.Dropout(0.1)(x)\n",
        "outputs = keras.layers.Dense(2)(x)\n",
        "model = keras.Model(inputs=inputs, outputs=outputs, name=\"bert_dense\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jdEKgMz2oKSW"
      },
      "outputs": [],
      "source": [
        "backbone.trainable = False\n",
        "sequence = backbone(inputs)[\"sequence_output\"]\n",
        "for _ in range(3):  #\n",
        "    sequence = keras_nlp.layers.TransformerEncoder(\n",
        "        num_heads=4,\n",
        "        intermediate_dim=256,\n",
        "        dropout=0.1,\n",
        "    )(sequence)\n",
        "\n",
        "x = keras.layers.Dense(128, activation=\"relu\")(sequence[:, backbone.cls_token_index, :])\n",
        "outputs = keras.layers.Dense(2)(x)\n",
        "model = keras.Model(inputs=inputs, outputs=outputs, name=\"bert_transformer\")\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JlKn50KH28np"
      },
      "outputs": [],
      "source": [
        "model,history = bert_compile_and_fit(model)\n",
        "# Takes approximately 1560s (ES on epoch 6) on a T4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KG_6SGbUD3QJ"
      },
      "outputs": [],
      "source": [
        "test_loss, test_acc =  model.evaluate(imdb_test_preprocessed, verbose=0)\n",
        "print(f'Model {model.name} test accuracy: {test_acc:.3f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N5cYPJ4CDyPs"
      },
      "outputs": [],
      "source": [
        "# See what the model say about the test sentences\n",
        "tspred = model.predict(preprocessor(test_sentences), verbose=0)\n",
        "for ix in range(len(tspred)):\n",
        "  sm =keras.activations.softmax(tspred[ix])\n",
        "  print(f'{sm[1]:.2f} -- {test_sentences[ix]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_fz9OaBa0Acu"
      },
      "source": [
        "Due to limited computational resources, I was unable to test all experimental designs, especially models with more complex structures that require extended training time on GPUs. However, I conducted experiments on a multi-layer TransformerEncoder structure and a simple Dense structure. These models showed lower accuracy compared to the pre-trained BERT classifier, likely due to limited tuning of hyperparameters and fewer computational resources for extensive training.\n",
        "\n",
        "Based on my experiments, I could not identify a top layer that outperformed the pre-trained BERT classifier. While adding multiple TransformerEncoder layers improved upon the simple Dense structure, the performance was still significantly lower. The pre-trained model remains the best choice for this task.\n",
        "\n",
        "| **Model**                     | **Test Accuracy** | **Notes**                                                                                                                                      |\n",
        "|-------------------------------|-------------------|------------------------------------------------------------------------------------------------------------------------------------------------|\n",
        "| Pre-trained BERT Classifier   | **0.897**         | Achieved the best performance due to transfer learning and optimized layers.                                                                  |\n",
        "| Multi-layer TransformerEncoder| 0.735             | Lower performance, likely due to insufficient fine-tuning and simpler architecture compared to pre-trained BERT.                              |\n",
        "| Simple Dense Structure         | ~0.70             | Struggled with capturing complex relationships in the data. Demonstrated that pre-trained embeddings are critical for better performance.      |\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "1. **Best Performance**: The pre-trained BERT model with `bert_small_en_uncased` achieved the highest accuracy of **0.894** on the test set. Its success is attributed to transfer learning, leveraging rich contextual embeddings and fine-tuning on a large corpus. This model is highly effective and reliable for sentiment classification.\n",
        "\n",
        "2. **Comparison with `bert_tiny_en_uncased`**: The `bert_tiny_en_uncased` model achieved a test accuracy of **0.843**, showing a trade-off between model size and performance. While it is computationally lighter, it lacks the depth and capacity of the `bert_small_en_uncased` model.\n",
        "\n",
        "3. **Custom Top Layers**: Experiments with additional custom layers (e.g., multi-layer TransformerEncoder, Dense structures) on `bert_tiny_en_uncased` yielded lower accuracy (~0.735). These layers struggled to match the performance of the pre-trained classifier due to insufficient complexity and contextual understanding.\n",
        "\n",
        "4. **Conclusion**: The `bert_small_en_uncased` model is the optimal choice for this task, demonstrating superior accuracy and robustness. Simpler architectures or smaller models, while faster, lack the same level of effectiveness. Further improvements could involve fine-tuning the last few layers of the pre-trained models or experimenting with hybrid architectures, but the pre-trained BERT remains the most reliable solution."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}